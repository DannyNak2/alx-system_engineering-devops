Scale Up – Highly Available Web Infrastructure
Architecture Diagram (Text Form)

               Internet
                   |
        +----------------------+
        |   HAProxy LB #1      |
        +----------------------+
                   |
        +----------------------+
        |   HAProxy LB #2      |
        +----------------------+
         /         |         \
        /          |          \
+-----------+ +-----------+ +-----------+
| Web Server| | Web Server| | Web Server|
|  (Nginx)  | |  (Nginx)  | |  (Nginx)  |
+-----------+ +-----------+ +-----------+
     |             |            |
     |             |            |
+-----------+ +-----------+ +-----------+
| App Server| | App Server| | App Server|
+-----------+ +-----------+ +-----------+
     \             |            /
      \            |           /
       \           |          /
        +-------------------+
        |   DB Primary      |
        +-------------------+
                 |
        +-------------------+
        |   DB Replica      |
        +-------------------+

Additional Elements and Why They Are Added
Extra Load Balancer (HAProxy #2)

Works in a clustered setup with Load Balancer #1 for high availability.

If one load balancer fails, the other takes over automatically.

Prevents the load balancer from being a single point of failure.

Dedicated Web Server(s)

Runs Nginx to handle static content and reverse-proxy requests to application servers.

Isolating web servers means web traffic handling doesn’t interfere with application logic.

Dedicated Application Server(s)

Runs backend code and business logic.

Keeps CPU-intensive processing separate from web content delivery.

Allows independent scaling of the application layer.

Dedicated Database Server(s)

Primary DB handles all writes.

Replica DB handles read requests to improve performance and availability.

Isolation ensures that DB performance is not degraded by other workloads.

How the Load Balancer Cluster Works
Active-Passive Configuration:
Only one load balancer handles traffic at a time; the second stands by and takes over on failure.

Active-Active Configuration:
Both load balancers share traffic simultaneously, increasing throughput.

Failover: Managed using tools like Keepalived or VRRP, which assign a virtual IP that switches between load balancers.

Why Split Components onto Separate Servers
Better Performance: Each tier (web, app, DB) can be optimized for its workload.

Easier Scaling: You can scale only the tier that needs more resources (e.g., add more app servers if processing is slow).

Security Benefits: Sensitive DBs can be isolated from direct internet access.

Fault Isolation: Failure in one tier doesn’t directly affect the others.

Application Server vs Web Server
Web Server (e.g., Nginx, Apache):
Handles HTTP(S) requests, serves static files, and forwards dynamic requests to application servers.

Application Server (e.g., Gunicorn, uWSGI, Node.js runtime):
Runs the backend application logic, processes requests, interacts with databases, and returns responses to the web server.

This setup allows horizontal scaling (adding more servers to each tier) and high availability (redundancy in load balancers and DB replication).